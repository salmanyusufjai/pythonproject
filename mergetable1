from google.cloud import bigquery
from collections import defaultdict

# Initialize a BigQuery client
client = bigquery.Client()

# Master table information
master_table = "project.dataset.master_table"

# Your table dictionary
table_dict = [
    {'retro_date': '2023-01-01', 'output_table_name': 'project.dataset.table1_ebi'},
    {'retro_date': '2023-01-01', 'output_table_name': 'project.dataset.table2_ccds'},
    {'retro_date': '2023-01-01', 'output_table_name': 'project.dataset.table3'},
    {'retro_date': '2023-02-01', 'output_table_name': 'project.dataset.table4_ebi'},
    {'retro_date': '2023-02-01', 'output_table_name': 'project.dataset.table5_ccds'}
]

# Load exclusion rules from the configuration
exclusion_config = {
    'ebi': ['companyid', 'crn'],
    'ccds': ['companyid', 'id'],
    # Define more table types and their excluded columns if needed
}

# Step 1: Group tables by retro_date
grouped_tables = defaultdict(list)
for entry in table_dict:
    retro_date = entry['retro_date']
    grouped_tables[retro_date].append(entry)

# Helper function to extract alias name from the full table name
def get_alias_name(full_table_name):
    # Extract alias (table name without project and dataset)
    return full_table_name.split('.')[-1]

# Helper function to detect table type from the name
def get_table_type(full_table_name):
    if "ebi" in full_table_name:
        return 'ebi'
    elif "ccds" in full_table_name:
        return 'ccds'
    else:
        return 'default'

# Function to generate the SQL excluding specific columns
def generate_sql_with_exclusions(table_name, alias_name, exclude_columns):
    # Use the EXCEPT clause in SQL to exclude the specified columns
    exclude_clause = ', '.join([col for col in exclude_columns])
    return f"SELECT * EXCEPT({exclude_clause}) FROM `{table_name}` AS {alias_name}"

# Function to process each group
def process_group(rundate, tables):
    # Identify the table that contains 'ebi' in its name
    ebi_table = None
    other_tables = []
    
    for table_entry in tables:
        table_type = get_table_type(table_entry['output_table_name'])
        if table_type == 'ebi':
            ebi_table = table_entry
        else:
            other_tables.append(table_entry)
    
    if not ebi_table:
        raise ValueError(f"No 'ebi' table found for rundate {rundate}")
    
    # Step 2: Build the SQL query dynamically based on columns to exclude
    ebi_table_alias = get_alias_name(ebi_table['output_table_name'])
    ebi_exclude_columns = exclusion_config.get('ebi', ['companyid'])  # Default to excluding companyid if not found
    ebi_exclusions = generate_sql_with_exclusions(ebi_table['output_table_name'], ebi_table_alias, ebi_exclude_columns)

    query = f"""
    -- Get companyid from master table
    WITH master AS (
        SELECT companyid FROM `{master_table}`
    ),
    -- Get data from ebi table excluding specified columns
    ebi_data AS (
        {ebi_exclusions}
        WHERE companyid IN (SELECT companyid FROM master)
    )
    """
    
    # Add other tables dynamically with their exclusion rules
    for table_entry in other_tables:
        table_alias = get_alias_name(table_entry['output_table_name'])
        table_type = get_table_type(table_entry['output_table_name'])
        exclude_columns = exclusion_config.get(table_type, ['companyid'])  # Default to excluding companyid
        exclusions = generate_sql_with_exclusions(table_entry['output_table_name'], table_alias, exclude_columns)
        query += f""",
        {table_alias}_data AS (
            {exclusions}
            WHERE companyid IN (SELECT companyid FROM master)
        )
        """
    
    # Final SELECT to combine data
    query += f"""
    SELECT master.companyid, ebi_data.*, 
    """
    query += ", ".join([f"{get_alias_name(table_entry['output_table_name'])}_data.*" for table_entry in other_tables])  # Add other table data columns
    query += f"""
    FROM master
    LEFT JOIN ebi_data ON master.companyid = ebi_data.companyid
    """
    
    for table_entry in other_tables:
        table_alias = get_alias_name(table_entry['output_table_name'])
        query += f"LEFT JOIN {table_alias}_data ON master.companyid = {table_alias}_data.companyid\n"

    # Step 4: Execute the query and save the result into a new table
    new_table_name = f"project.dataset.new_table_{rundate.replace('-', '_')}"
    job_config = bigquery.QueryJobConfig(destination=new_table_name)
    
    query_job = client.query(query, job_config=job_config)
    query_job.result()  # Wait for the query to complete
    
    print(f"New table created: {new_table_name}")

# Step 5: Process each group by retro_date
for rundate, tables in grouped_tables.items():
    process_group(rundate, tables)
